# エージェント

### 定義

エージェントアシスタントは、大規模言語モデルの推論能力を活用し、複雑な人間のタスクを自律的に目標設定、タスク分解、ツールの呼び出し、プロセスの反復を行い、人間の介入なしでタスクを完了することができます。

### エージェントアシスタントの使い方

迅速に使い始めるために、「探索」でエージェントアシスタントのアプリケーションテンプレートを見つけて自分のワークスペースに追加するか、それを基にカスタマイズすることができます。新しいDifyスタジオでは、ゼロから自分専用のエージェントアシスタントを編成し、財務報告書の分析、レポートの作成、ロゴデザイン、旅行計画などのタスクを完了する手助けをすることができます。

<figure><img src="../../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption><p>探索 - エージェントアシスタントアプリケーションテンプレート</p></figcaption></figure>

「スタジオ - アシスタント型アプリケーション」でエージェントアシスタントを選択すると編成を開始できます。

<figure><img src="../../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption><p>スタジオ - エージェントアシスタントの構築</p></figcaption></figure>

エージェントアシスタントの推論モデルを選択します。エージェントアシスタントのタスク完了能力はモデルの推論能力に依存しますので、より強力な推論能力を持つモデルシリーズ、例えばgpt-4を選択することをお勧めします。これにより、より安定したタスク完了効果が得られます。

<figure><img src="../../.gitbook/assets/image (5) (1) (1).png" alt=""><figcaption><p>エージェントアシスタントの推論モデルを選択</p></figcaption></figure>

「プロンプト」でエージェントアシスタントの指示を作成できます。より良い結果を得るために、指示の中でタスクの目標、ワークフロー、リソース、制約などを明確にすることが重要です。

<figure><img src="../../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption><p>エージェントアシスタントの指示プロンプトを編成</p></figcaption></figure>

### アシスタントに必要なツールを追加

「コンテキスト」では、エージェントアシスタントが参照できるナレッジベースツールを追加できます。これにより、外部の背景知識を取得することができます。

「ツール」では、使用する必要があるツールを追加できます。ツールはLLMの能力を拡張し、例えばネット検索、科学計算、画像の作成などが可能になります。これにより、LLMは外部世界と接続する能力を持つようになります。Difyは2種類のツールタイプを提供しています：**ファーストパーティツール**と**カスタムツール**です。

Difyエコシステムが提供するファーストパーティ内蔵ツールを直接使用するか、カスタムAPIツール（現在はOpenAPI / SwaggerおよびOpenAIプラグイン規格をサポート）を簡単にインポートすることができます。

<figure><img src="../../.gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption><p>アシスタントに必要なツールを追加</p></figcaption></figure>

ツールを使用すると、Dify上でより強力なAIアプリケーションを作成できます。例えば、エージェントアシスタント型アプリケーションに適したツールを編成することで、タスクの推論、ステップの分解、ツールの呼び出しを通じて複雑なタスクを完了できます。さらに、ツールを使用して他のシステムやサービスと接続し、外部環境と対話することも容易です。例えば、コードの実行や特定の情報源へのアクセスなどです。

### エージェントの設定

DifyではエージェントアシスタントにFunction Calling（関数呼び出し）とReActの2つの推論モードを提供しています。関数呼び出しをサポートするモデルシリーズ（例：gpt-3.5/gpt-4）はより良い、安定したパフォーマンスを持っています。関数呼び出しをサポートしていないモデルシリーズには、ReAct推論フレームワークで類似の効果を実現しています。

エージェント設定では、アシスタントのイテレーション制限を変更できます。

<figure><img src="../../.gitbook/assets/image (11).png" alt=""><figcaption><p>Function Calling モード</p></figcaption></figure>

<figure><img src="../../.gitbook/assets/image (13).png" alt=""><figcaption><p>ReAct モード</p></figcaption></figure>

### 会話のオープニング設定

エージェントアシスタントの会話オープニングとオープニング質問を設定できます。設定された会話オープニングは、ユーザーが初めて対話を開始する際に、アシスタントが完了できるタスクや提案される質問の例を表示します。

<figure><img src="../../.gitbook/assets/image (4) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption><p>会話のオープニングとオープニング質問を設定</p></figcaption></figure>

### デバッグとプレビュー

エージェントアシスタントの編成が完了したら、アプリとして公開する前にデバッグとプレビューを行い、アシスタントのタスク完了効果を確認できます。

<figure><img src="../../.gitbook/assets/image (7) (1).png" alt=""><figcaption><p>デバッグとプレビュー</p></figcaption></figure>

### アプリの公開

<figure><img src="../../.gitbook/assets/image (8) (1).png" alt=""><figcaption><p>アプリをWebアプリとして公開</p></figcaption></figure>